{"cells":[{"cell_type":"markdown","source":["# EDA steps:\n•\tImport the Data-set\n•\tslicing data\n•\tCheck data characters\n•\tcalculating statistics: mean, median, standard deviation\n•\tbasic plotting for data\n•\tCorrelation computation\n\nData pre-processing steps:\n•\tCheck out and filled the missing values\n•\tImport the Libraries\n•   Read the bureau data\n•\tHandle /Create Dummy variable\n•   Group by function\n•   Logistic Regrssion\n•\tDimensionality reduction\n•\tClustering of similar observations"],"metadata":{}},{"cell_type":"code","source":["# Import the Data-set & Import the Libraries"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# numpy and pandas for data manipulation\nimport pandas as pd\nimport numpy as np\n# matplotlib and seaborn for plotting\nimport matplotlib\nimport matplotlib.pyplot as plt \nimport seaborn as sns "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Read Data"],"metadata":{}},{"cell_type":"code","source":["app_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_test = pd.read_csv(\"/dbfs/FileStore/tables/application_test.csv\", header='infer')\nbureau = pd.read_csv(\"/dbfs/FileStore/tables/bureau.csv\", header='infer')\nbureau_balance = pd.read_csv(\"/dbfs/FileStore/tables/bureau_balance.csv\", header='infer')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Slicing data"],"metadata":{}},{"cell_type":"markdown","source":["Check data characters & calculating statistics: mean, median, standard deviation"],"metadata":{}},{"cell_type":"code","source":["app_train['TARGET'].value_counts()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print('AMT_INCOME_TOTAL Train',app_train['AMT_INCOME_TOTAL'].count())"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["basic plotting for data"],"metadata":{}},{"cell_type":"code","source":["app_train['TARGET'].astype(int).plot.hist()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Correlation computation"],"metadata":{}},{"cell_type":"code","source":["# Find correlations with the target and sort\ncorrelations = app_train.corr()['TARGET'].sort_values()\n\n# Display correlations\nprint('Most Positive Correlations:\\n', correlations.tail(20))\nprint('\\nMost Negative Correlations:\\n', correlations.head(20))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Correlation Heat Map"],"metadata":{}},{"cell_type":"code","source":["ext_data = app_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\next_data_corrs = ext_data.corr()\next_data_corrs\n\nplt.figure(figsize = (8, 6))\n\n# Heatmap of correlations\nsns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot = True, vmax = 0.6)\nplt.title('Correlation Heatmap');"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["Check out and filled the missing values"],"metadata":{}},{"cell_type":"code","source":["# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[" # Missing values statistics\nmissing_values = missing_values_table(app_train)\nmissing_values.head(20)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["Exploration of Bureau Data"],"metadata":{}},{"cell_type":"markdown","source":["Import the Libraries"],"metadata":{}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import Imputer \nfrom sklearn.preprocessing import scale \n# Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["Group By Function"],"metadata":{}},{"cell_type":"code","source":["# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\nprevious_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\nprevious_loan_counts.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">206</span><span class=\"ansired\">]: </span>\n   SK_ID_CURR  previous_loan_counts\n0      100001                     7\n1      100002                     8\n2      100003                     4\n3      100004                     2\n4      100005                     3\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["# app_train left join previous loan data\ntrain = app_train.join(previous_loan_counts, on = 'SK_ID_CURR', how = 'left', lsuffix='SK_ID_CURR', rsuffix='r_SK_ID_CURR')\n\n# Fill the missing values with 0 \ntrain['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\ntrain.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">207</span><span class=\"ansired\">]: </span>\n   SK_ID_CURRSK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n0                100002       1         Cash loans           M            N   \n1                100003       0         Cash loans           F            N   \n2                100004       0    Revolving loans           M            Y   \n3                100006       0         Cash loans           F            N   \n4                100007       0         Cash loans           M            N   \n\n  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n0               Y             0          202500.0    406597.5      24700.5   \n1               N             0          270000.0   1293502.5      35698.5   \n2               Y             0           67500.0    135000.0       6750.0   \n3               Y             0          135000.0    312682.5      29686.5   \n4               Y             0          121500.0    513000.0      21865.5   \n\n           ...           FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n0          ...                          0                0   \n1          ...                          0                0   \n2          ...                          0                0   \n3          ...                          0                0   \n4          ...                          0                0   \n\n  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n0                        0.0                       0.0   \n1                        0.0                       0.0   \n2                        0.0                       0.0   \n3                        NaN                       NaN   \n4                        0.0                       0.0   \n\n  AMT_REQ_CREDIT_BUREAU_WEEK AMT_REQ_CREDIT_BUREAU_MON  \\\n0                        0.0                       0.0   \n1                        0.0                       0.0   \n2                        0.0                       0.0   \n3                        NaN                       NaN   \n4                        0.0                       0.0   \n\n   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n0                        0.0                         1.0   \n1                        0.0                         0.0   \n2                        0.0                         0.0   \n3                        NaN                         NaN   \n4                        0.0                         0.0   \n\n   SK_ID_CURRr_SK_ID_CURR  previous_loan_counts  \n0                216379.0                   1.0  \n1                216380.0                   8.0  \n2                216381.0                   4.0  \n3                216383.0                   2.0  \n4                216384.0                   2.0  \n\n[5 rows x 124 columns]\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\nprint('Training Features shape: ', train.shape)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Features shape:  (307511, 124)\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["train_labels = app_train['TARGET']\n\n# Align the training and testing data, keep only columns present in both dataframes\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\n# Add the target back in\napp_train['TARGET'] = train_labels\n\nprint('Training Features shape: ', app_train.shape)\nprint('Testing Features shape: ', app_test.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Features shape:  (307511, 243)\nTesting Features shape:  (48744, 242)\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["# Logistic Regression\nfrom sklearn.preprocessing import MinMaxScaler, Imputer\n# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\n# Match the columns in the dataframes\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\nprint('Training shape: ', app_train.shape)\nprint('Testing shape: ', app_test.shape)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training shape:  (307511, 242)\nTesting shape:  (48744, 242)\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\nprint('Training set full shape: ', app_train.shape)\nprint('Testing set full shape: ' , app_test.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training set full shape:  (307511, 242)\nTesting set full shape:  (48744, 242)\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["# Copy of the testing data\napp_test = app_test.copy()\n\n# Median imputation of missing values\nimputer = Imputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# Fit on the training data\nimputer.fit(app_train)\n\n# Transform both training and testing data\napp_train = imputer.transform(app_train)\napp_test = imputer.transform(app_test)\n\n# Repeat with the scaler\nscaler.fit(app_train)\napp_train = scaler.transform(app_train)\napp_test = scaler.transform(app_test)\n\nprint('Training data shape: ', app_train.shape)\nprint('Testing data shape: ', app_test.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training data shape:  (307511, 242)\nTesting data shape:  (48744, 242)\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C = 0.0001)\n\n# Train on the training data\nlog_reg.fit(app_train, train_labels)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">216</span><span class=\"ansired\">]: </span>\nLogisticRegression(C=0.0001, class_weight=None, dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=100,\n          multi_class=&apos;ovr&apos;, n_jobs=1, penalty=&apos;l2&apos;, random_state=None,\n          solver=&apos;liblinear&apos;, tol=0.0001, verbose=0, warm_start=False)\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\napp_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_test = pd.read_csv(\"/dbfs/FileStore/tables/application_test.csv\", header='infer')"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Naive Bayes\napp_train = pd.get_dummies(app_train)\n# Match the columns in the dataframes\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\nprint('Training shape: ', app_train.shape)\nprint('Testing shape: ', app_test.shape)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# Split dataset in training and test datasets\nX_train, X_test = train_test_split(app_train, test_size=0.3, random_state = 0)\n\n# fit a Naive Bayes model to the data\nmodel = GaussianNB()\nmodel.fit(X_train, X_test)\nprint(model)\n# make predictions\nexpected = X_test\npredicted = model.predict(X_train)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["# Decision Tree Classifier\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\n\n# load the datasets\napp_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_train = pd.get_dummies(app_train)\napp_train.dropna()\n\n# Split dataset in training and test datasets\nX_train, X_test = train_test_split(app_train, test_size=0.3, random_state = 0)\n\n# fit a CART model to the data\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, X_test)\nprint(model)\n\n# make predictions\nexpected = X_test.target\npredicted = model.predict(X_train)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Support Vector Machine\nfrom sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\n# load the datasets\napp_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_train = pd.get_dummies(app_train)\napp_train.dropna()\n# Split dataset in training and test datasets\nX_train, X_test = train_test_split(app_train, test_size=0.3, random_state = 0)\n# fit a SVM model to the data\nmodel = SVC()\nmodel.fit(X_train, X_test)\nprint(model)\n# make predictions\nexpected = X_test\npredicted = model.predict(X_train)\n# summarize the fit of the model\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Make the random forest classifier\nrandom_forest = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["random_forest.fit(app_train, train_labels)\n\n# Extract feature importances\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n\n# Make predictions on the test data\npredictions = random_forest.predict_proba(app_test)[:, 1]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.3s\n[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   54.1s finished\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    1.0s finished\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["# AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier #For Classification\nfrom sklearn.ensemble import AdaBoostRegressor #For Regression\nfrom sklearn.tree import DecisionTreeClassifier\n\n# load the datasets\napp_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_train = pd.get_dummies(app_train)\napp_train.dropna(how=\"all\", inplace=True)\n\n# Split dataset in training and test datasets\napp_train_train, app_train_test, X, y = train_test_split(app_train, predict, test_size = 0.25, random_state = 42)\ndt = DecisionTreeClassifier() \nclf = AdaBoostClassifier(n_estimators=100, base_estimator=dt,learning_rate=1)\n\n# Above I have used decision tree as a base estimator, you can use any ML learner as base estimator if it ac# cepts sample weight \nclf.fit(app_train, predict)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["#PCA"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["#PCA\n# pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# matplotlit and seaborn for visualizations\nimport matplotlib.pyplot as plt\nplt.rcParams['font.size'] = 22\nimport seaborn as sns\n\n# Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.pipeline import Pipeline\n\napp_train = pd.read_csv(\"/dbfs/FileStore/tables/application_train.csv\", header='infer')\napp_test = pd.read_csv(\"/dbfs/FileStore/tables/application_test.csv\", header='infer')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":40},{"cell_type":"code","source":["# Train missing values (in percent)\napp_train_missing = (app_train.isnull().sum() / len(app_train)).sort_values(ascending = False)\napp_train_missing.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">221</span><span class=\"ansired\">]: </span>\nCOMMONAREA_MEDI             0.698723\nCOMMONAREA_AVG              0.698723\nCOMMONAREA_MODE             0.698723\nNONLIVINGAPARTMENTS_MODE    0.694330\nNONLIVINGAPARTMENTS_MEDI    0.694330\ndtype: float64\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["# Test missing values (in percent)\napp_test_missing = (app_test.isnull().sum() / len(app_test)).sort_values(ascending = False)\napp_test_missing.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">222</span><span class=\"ansired\">]: </span>\nCOMMONAREA_MEDI             0.687161\nCOMMONAREA_AVG              0.687161\nCOMMONAREA_MODE             0.687161\nNONLIVINGAPARTMENTS_MODE    0.684125\nNONLIVINGAPARTMENTS_MEDI    0.684125\ndtype: float64\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":[" # One hot encoding\napp_train = pd.get_dummies(app_train)\napp_test = pd.get_dummies(app_test)\n\n# Match the columns in the dataframes\napp_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\nprint('Training shape: ', app_train.shape)\nprint('Testing shape: ', app_test.shape)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training shape:  (307511, 242)\nTesting shape:  (48744, 242)\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n\nprint('Training set full shape: ', app_train.shape)\nprint('Testing set full shape: ' , app_test.shape)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training set full shape:  (307511, 242)\nTesting set full shape:  (48744, 242)\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["# Make a pipeline with imputation and pca\npipeline = Pipeline(steps = [('imputer', Imputer(strategy = 'median')),\n             ('pca', PCA())])\n\n# Fit and transform on the training data\napp_train_pca = pipeline.fit_transform(app_train)\n\n# transform the testing data\napp_test_pca = pipeline.transform(app_test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["# Extract the pca object\npca = pipeline.named_steps['pca']\n\n# Plot the cumulative variance explained\n\nplt.figure(figsize = (10, 8))\nplt.plot(list(range(app_train.shape[1])), np.cumsum(pca.explained_variance_ratio_), 'r-')\nplt.xlabel('Number of PC'); plt.ylabel('Cumulative Variance Explained');\nplt.title('Cumulative Variance Explained with PCA');"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","nbconvert_exporter":"python","file_extension":".py"},"name":"Home Credit","notebookId":498798941979496},"nbformat":4,"nbformat_minor":0}
